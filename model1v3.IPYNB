{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import unique\n",
    "from scipy.sparse.construct import rand\n",
    "from sklearn.utils import shuffle\n",
    "import medical_lib as ml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filled_noStr.csv')\n",
    "df = df.iloc[:, 1:]\n",
    "print(df.head())\n",
    "\n",
    "tot = pd.read_csv('Verstorben.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Filled_noStr.csv' wird in zwei Datasets geteilt.\n",
    "Df1 enthält nur die Toten. Df2 enthält nur die Lebenden.\n",
    "Anschliessend werden die Daten von 94 Toten und 94 Lebenden zusammengeführt und die Daten der restlichen 20 Toten und restlichen Lebenden separat vereinigt.\n",
    "\n",
    "Diese beiden Dataframes werden später Train und Testset sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquetote = tot['Pseudonym'].unique().tolist()\n",
    "df1 = df[df['Pseudonym'].isin(uniquetote)] #Dataframe nur mit den Toten\n",
    "df2 = df[~df['Pseudonym'].isin(uniquetote)] #Dataframe nur mit den Lebenden\n",
    "uniquelebende = df2['Pseudonym'].unique().tolist() #Liste aller distinct Lebende\n",
    "\n",
    "uniquetote1 = uniquetote[0:(len(uniquetote)-20)] #Liste aus 94 tote\n",
    "uniquetote2 = uniquetote[len(uniquetote)-20: len(uniquetote)] #Liste der restlichen 20tote\n",
    "\n",
    "uniquelebende1 = uniquelebende[0: 94] #Liste aus 94Lebende\n",
    "uniquelebende2 = uniquelebende[94:len(uniquelebende)] # Liste der restlichen Lebenden\n",
    "\n",
    "beides_Train = uniquetote1 + uniquelebende1\n",
    "beides_Test = uniquetote1 + uniquelebende2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1v3_train = df[df['Pseudonym'].isin(beides_Train)] # Dataframe aus 94tote und 94lebende. Komplettes Train-Set\n",
    "df1v3_Test = df[df['Pseudonym'].isin(beides_Test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1v3_train = df[df['Pseudonym'].isin(beides_Train)] # Dataframe aus 94tote und 94lebende. Komplettes Train-Set\n",
    "df1v3_Test = df[df['Pseudonym'].isin(beides_Test)]\n",
    "df1v3_train.to_csv('model1v3trainunfilled.csv')\n",
    "df1v3_Test.to_csv('model1v3testunfilled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fülle model1v3trainunfilled mit den Werten direkt nach OP, d.h. entweder an Tag 0, falls Wert vorhanden, oder unmittelbar danach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model1v3trainunfilled.csv')\n",
    "df = df.iloc[:, 1:]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jeden Patienten: Nehme einen Ausschnitt von Tag 0 bis 100 aus dem Datensatz als neues Dataframe. Gehe durch alle Zeilen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takefreshop(inputDF, pseudo):\n",
    "    dffilled = inputDF.copy()\n",
    "    p = dffilled[dffilled['Pseudonym'] == pseudo]\n",
    "    p.sort_values(by='relatives_datum', ascending=True, inplace=True)\n",
    "    col = dffilled.columns\n",
    "    # tmp.to_csv('0.csv')\n",
    "    naive = pd.DataFrame(columns=col)\n",
    "    abkuset = set()\n",
    "    for row in range(0, len(p)):\n",
    "        for col in range(0, len(p.columns)):\n",
    "            value = p.iloc[row, col]\n",
    "            if (np.isnan(value) == False) and (abkuset.__contains__(p.columns[col]) == False): \n",
    "                naive.loc[0, p.columns[col]] = value\n",
    "                abkuset.add(p.columns[col])\n",
    "                continue\n",
    "                \n",
    "    return naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erstelle Dataframe, in der für jeden Patienten nur sein aktuellster Wert pro Feature benutzt wird\n",
    "inputDf = 'model1v3trainunfilled.csv'\n",
    "outputDf = 'model1v3train_Filled.csv'\n",
    "        \n",
    "\n",
    "df = pd.read_csv(inputDf)\n",
    "df = df.iloc[:, 1:]\n",
    "op = df[df['relatives_datum'].between(0,100)]\n",
    "pseudolist = df['Pseudonym'].unique()\n",
    "frames = []\n",
    "i = 0\n",
    "for name in pseudolist:\n",
    "    tmp = takefreshop(op, name)\n",
    "    frames.append(tmp)\n",
    "    i += 1\n",
    "result = pd.concat(frames)\n",
    "# result.to_csv(outputDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudonym relatives_datum    CA    CREA   CRP   ERY   EVB  GGT37 GOT37  \\\n",
      "0       0.0             0.0  1.99  0.6801  2.61  3.54  13.7  284.0  86.0   \n",
      "0      79.0             0.0  1.89  0.5501  0.61  2.67  12.8   38.0   7.0   \n",
      "0     124.0             0.0  2.11  0.4101  1.01  2.77  18.7  112.0  10.0   \n",
      "0     247.0             0.0  2.26  0.5501  1.66  2.95  24.2  104.0  88.0   \n",
      "0     997.0             0.0  2.45  0.8501  0.97  3.32  15.9  167.0  15.0   \n",
      "\n",
      "   GPT37  ...   IL-6 G.APTT G.QUICK   IRF CA-KORR NRBC-ABS FK-RO IG-ABS  \\\n",
      "0  254.0  ...    NaN    NaN     NaN   NaN     NaN      NaN   NaN    NaN   \n",
      "0   20.0  ...   8.72   22.9    71.7   1.2    2.24     0.03  5.08    0.1   \n",
      "0   20.0  ...   99.6   26.1    77.0   0.0  2.3325     0.03   NaN   0.11   \n",
      "0   33.0  ...  54.47   31.3    80.6  21.2  2.3275     0.05   1.0    NaN   \n",
      "0   34.0  ...   5.29   29.3    85.9  53.9  2.4325     0.03  9.94   0.13   \n",
      "\n",
      "  IG-REL   CSA-RO  \n",
      "0    NaN      NaN  \n",
      "0    2.8      NaN  \n",
      "0    1.7      NaN  \n",
      "0    NaN  30.0001  \n",
      "0    2.5      NaN  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result.head())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
