{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import unique\n",
    "from scipy.sparse.construct import rand\n",
    "from sklearn.utils import shuffle\n",
    "import medical_lib as ml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filled_noStr.csv')\n",
    "df = df.iloc[:, 1:]\n",
    "\n",
    "tot = pd.read_csv('Verstorben.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Filled_noStr.csv' wird in zwei Datasets geteilt.\n",
    "Df1 enthält nur die Toten. Df2 enthält nur die Lebenden.\n",
    "Anschliessend werden die Daten von 94 Toten und 94 Lebenden zusammengeführt und die Daten der restlichen 20 Toten und restlichen Lebenden separat vereinigt.\n",
    "\n",
    "Diese beiden Dataframes werden später Train und Testset sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquetote = tot['Pseudonym'].unique().tolist()\n",
    "df1 = df[df['Pseudonym'].isin(uniquetote)] #Dataframe nur mit den Toten\n",
    "df2 = df[~df['Pseudonym'].isin(uniquetote)] #Dataframe nur mit den Lebenden\n",
    "uniquelebende = df2['Pseudonym'].unique().tolist() #Liste aller distinct Lebende\n",
    "\n",
    "uniquetote1 = uniquetote[0:(len(uniquetote)-20)] #Liste aus 94 tote\n",
    "uniquetote2 = uniquetote[len(uniquetote)-20: len(uniquetote)] #Liste der restlichen 20tote\n",
    "\n",
    "uniquelebende1 = uniquelebende[0: 94] #Liste aus 94Lebende\n",
    "uniquelebende2 = uniquelebende[94:len(uniquelebende)] # Liste der restlichen Lebenden\n",
    "\n",
    "beides_Train = uniquetote1 + uniquelebende1\n",
    "beides_Test = uniquetote2 + uniquelebende2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.0, 124.0, 997.0, 1056.0, 1256.0, 1494.0, 1938.0, 2500.0, 2568.0, 2628.0, 2652.0, 2832.0, 3297.0, 3443.0, 4747.0, 5190.0, 5650.0, 6360.0, 6658.0, 7270.0, 8275.0, 8757.0, 9208.0, 9280.0, 9382.0, 9457.0, 9688.0, 11288.0, 11337.0, 11862.0, 12889.0, 13243.0, 14199.0, 14284.0, 14313.0, 16272.0, 17201.0, 17461.0, 17644.0, 18298.0, 19124.0, 21470.0, 24004.0, 25619.0, 26792.0, 28982.0, 29771.0, 30799.0, 34317.0, 36408.0, 38115.0, 39361.0, 39821.0, 45533.0, 49425.0, 49549.0, 50241.0, 50549.0, 52103.0, 53045.0, 53597.0, 54990.0, 55973.0, 57100.0, 58182.0, 58330.0, 61647.0, 65046.0, 67097.0, 68828.0, 70129.0, 71972.0, 73327.0, 74731.0, 74829.0, 77315.0, 77399.0, 78667.0, 80660.0, 84739.0, 85038.0, 88652.0, 88891.0, 89548.0, 90576.0, 90921.0, 91210.0, 93051.0, 98569.0, 100030.0, 103967.0, 105083.0, 109351.0, 109365.0]\n",
      "\n",
      "[0, 247, 1068, 1090, 1235, 1414, 2848, 3487, 4811, 5865, 7233, 8440, 8730, 9828, 10037, 11849, 18425, 22278, 23649, 34038, 43249, 46549, 50183, 53835, 55997, 65201, 66153, 70862, 71242, 75011, 75756, 88775, 90326, 90836, 91102, 97831, 97875, 97896, 102395, 108556, 108560, 115135, 117122, 121883, 121992, 126150, 129784, 131293, 132559, 138631, 139733, 141378, 145421, 149121, 153152, 160758, 164028, 164720, 164722, 165637, 170102, 172954, 179563, 180192, 182214, 191305, 197629, 199491, 199768, 207620, 213765, 218249, 218700, 222605, 230667, 231763, 249985, 255576, 264955, 265696, 276359, 278289, 280462, 280549, 289322, 295113, 296988, 297726, 299227, 302096, 305091, 307036, 311805, 313781]\n"
     ]
    }
   ],
   "source": [
    "print(uniquelebende1)\n",
    "print('')\n",
    "print(uniquetote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1v3_train = df[df['Pseudonym'].isin(beides_Train)] # Dataframe aus 94tote und 94lebende. Komplettes Train-Set\n",
    "df1v3_Test = df[df['Pseudonym'].isin(beides_Test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1v3_train = df[df['Pseudonym'].isin(beides_Train)] # Dataframe aus 94tote und 94lebende. Komplettes Train-Set\n",
    "df1v3_Test = df[df['Pseudonym'].isin(beides_Test)]\n",
    "df1v3_train.to_csv('model1v3trainunfilled.csv')\n",
    "df1v3_Test.to_csv('model1v3testunfilled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fülle model1v3trainunfilled mit den Werten direkt nach OP, d.h. entweder an Tag 0, falls Wert vorhanden, oder unmittelbar danach.\n",
    "Mache dasselbe mit model1v3testunfilled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jeden Patienten: Nehme einen Ausschnitt von Tag 0 bis 100 aus dem Datensatz als neues Dataframe. Gehe durch alle Zeilen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takefreshop(inputDF, pseudo):\n",
    "    dffilled = inputDF.copy()\n",
    "    p = dffilled[dffilled['Pseudonym'] == pseudo]\n",
    "    p.sort_values(by='relatives_datum', ascending=True, inplace=True)\n",
    "    col = dffilled.columns\n",
    "    # tmp.to_csv('0.csv')\n",
    "    naive = pd.DataFrame(columns=col)\n",
    "    abkuset = set()\n",
    "    for row in range(0, len(p)):\n",
    "        for col in range(0, len(p.columns)):\n",
    "            value = p.iloc[row, col]\n",
    "            if (np.isnan(value) == False) and (abkuset.__contains__(p.columns[col]) == False): \n",
    "                naive.loc[0, p.columns[col]] = value\n",
    "                abkuset.add(p.columns[col])\n",
    "                continue\n",
    "                \n",
    "    return naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1v3trainunfilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erstelle Dataframe, in der für jeden Patienten nur sein aktuellster Wert pro Feature benutzt wird\n",
    "inputDf = 'model1v3trainunfilled.csv'\n",
    "outputDf = 'model1v3train_Filled.csv'\n",
    "        \n",
    "\n",
    "df = pd.read_csv(inputDf)\n",
    "df = df.iloc[:, 1:]\n",
    "op = df[df['relatives_datum'].between(0,100)]\n",
    "pseudolist = df['Pseudonym'].unique()\n",
    "frames = []\n",
    "i = 0\n",
    "for name in pseudolist:\n",
    "    tmp = takefreshop(op, name)\n",
    "    frames.append(tmp)\n",
    "    i += 1\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudonym relatives_datum    CA    CREA   CRP   ERY   EVB  GGT37 GOT37  \\\n",
      "0       0.0             0.0  1.99  0.6801  2.61  3.54  13.7  284.0  86.0   \n",
      "0      79.0             0.0  1.89  0.5501  0.61  2.67  12.8   38.0   7.0   \n",
      "0     124.0             0.0  2.11  0.4101  1.01  2.77  18.7  112.0  10.0   \n",
      "0     247.0             0.0  2.26  0.5501  1.66  2.95  24.2  104.0  88.0   \n",
      "0     997.0             0.0  2.45  0.8501  0.97  3.32  15.9  167.0  15.0   \n",
      "\n",
      "   GPT37  ...   IL-6 G.APTT G.QUICK   IRF CA-KORR NRBC-ABS FK-RO IG-ABS  \\\n",
      "0  254.0  ...    NaN    NaN     NaN   NaN     NaN      NaN   NaN    NaN   \n",
      "0   20.0  ...   8.72   22.9    71.7   1.2    2.24     0.03  5.08    0.1   \n",
      "0   20.0  ...   99.6   26.1    77.0   0.0  2.3325     0.03   NaN   0.11   \n",
      "0   33.0  ...  54.47   31.3    80.6  21.2  2.3275     0.05   1.0    NaN   \n",
      "0   34.0  ...   5.29   29.3    85.9  53.9  2.4325     0.03  9.94   0.13   \n",
      "\n",
      "  IG-REL   CSA-RO  \n",
      "0    NaN      NaN  \n",
      "0    2.8      NaN  \n",
      "0    1.7      NaN  \n",
      "0    NaN  30.0001  \n",
      "0    2.5      NaN  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(outputDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fehlende Werte für Tote werden mit Mittelwert der Toten und entsprechend bei den Lebenden aufgefüllt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model1v3train_Filled.csv')\n",
    "df = df.iloc[:, 1:]\n",
    "lebend = df[df['Pseudonym'].isin(uniquelebende1)]\n",
    "tot = df[df['Pseudonym'].isin(uniquetote1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lebend.columns[lebend.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "        lebend[i].fillna(lebend[i].mean(),inplace=True)\n",
    "for i in tot.columns[tot.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "        tot[i].fillna(tot[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [lebend, tot]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv('model1v3train_Filled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1v3testunfilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDf_test = 'model1v3testunfilled.csv'\n",
    "outputDf_test = 'model1v3test_Filled.csv'\n",
    "        \n",
    "\n",
    "df_test = pd.read_csv(inputDf_test)\n",
    "df_test = df_test.iloc[:, 1:]\n",
    "op_test = df_test[df_test['relatives_datum'].between(0,100)]\n",
    "pseudolist_test = df_test['Pseudonym'].unique()\n",
    "frames_test = []\n",
    "l = 0\n",
    "for name in pseudolist_test:\n",
    "    tmp = takefreshop(op_test, name)\n",
    "    frames_test.append(tmp)\n",
    "    l += 1\n",
    "result_test = pd.concat(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudonym relatives_datum    CA    CREA   CRP   ERY        EVB  GGT37 GOT37  \\\n",
      "0  111030.0             0.0  2.13  0.4901  3.54  3.29       18.5   71.0   8.0   \n",
      "0  112457.0             0.0  2.22  0.4301   0.1  2.93       18.5   54.0  17.0   \n",
      "0  113054.0             0.0  2.15  0.6701  0.33  2.76  16.299999   46.0  14.0   \n",
      "0  116887.0             0.0  2.18  0.7901  6.28  3.77       12.7   41.0  12.0   \n",
      "0  118338.0             0.0  2.14  0.6701  0.92  2.94       13.6  124.0  18.0   \n",
      "\n",
      "       GPT37  ...  IL-6 G.APTT G.QUICK  IRF CA-KORR NRBC-ABS  FK-RO IG-ABS  \\\n",
      "0        5.0  ...   NaN    NaN     NaN  NaN     NaN      NaN   9.11    NaN   \n",
      "0  71.900002  ...   NaN    NaN     NaN  NaN     NaN      NaN   4.61    NaN   \n",
      "0       22.0  ...   NaN    NaN     NaN  NaN     NaN      NaN    NaN    NaN   \n",
      "0       17.4  ...   NaN    NaN     NaN  NaN     NaN      NaN   14.3    NaN   \n",
      "0       20.7  ...  1.54   22.6   100.7  0.0     NaN     0.03  18.41   0.08   \n",
      "\n",
      "  IG-REL      CSA-RO  \n",
      "0    NaN         NaN  \n",
      "0    NaN         NaN  \n",
      "0    NaN  352.899994  \n",
      "0    NaN        30.0  \n",
      "0    1.0         NaN  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_test.head())\n",
    "result_test.to_csv(outputDf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model1v3test_Filled.csv')\n",
    "df = df.iloc[:, 1:]\n",
    "lebend = df[df['Pseudonym'].isin(uniquelebende2)]\n",
    "tot = df[df['Pseudonym'].isin(uniquetote2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lebend.columns[lebend.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "        lebend[i].fillna(lebend[i].mean(),inplace=True)\n",
    "for i in tot.columns[tot.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "        tot[i].fillna(tot[i].mean(),inplace=True)\n",
    "\n",
    "frames = [lebend, tot]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv('model1v3test_Filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDf = 'model1v3test_Filled.csv'\n",
    "statusDf = 'Verstorben.csv'\n",
    "\n",
    "        #Fügt Status zur InputDf hinzu\n",
    "ml.addStatusModel1(inputDf, statusDf)\n",
    "\n",
    "        #Füllt Spaltenweise NaNs mit dem Spaltenmittelwert\n",
    "df = pd.read_csv(inputDf)\n",
    "df = df.iloc[:, 2:]\n",
    "for i in df.columns[df.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "    df[i].fillna(df[i].mean(),inplace=True)\n",
    "df.to_csv(inputDf)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDf = 'model1v3train_Filled.csv'\n",
    "statusDf = 'Verstorben.csv'\n",
    "\n",
    "        #Fügt Status zur InputDf hinzu\n",
    "ml.addStatusModel1(inputDf, statusDf)\n",
    "\n",
    "        #Füllt Spaltenweise NaNs mit dem Spaltenmittelwert\n",
    "df = pd.read_csv(inputDf)\n",
    "df = df.iloc[:, 2:]\n",
    "for i in df.columns[df.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "    df[i].fillna(df[i].mean(),inplace=True)\n",
    "df.to_csv(inputDf) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
